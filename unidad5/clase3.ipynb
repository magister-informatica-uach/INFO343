{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<!-- Mejorar visualizaci贸n en proyector -->\n",
    "<style>\n",
    ".rendered_html {font-size: 1.2em; line-height: 150%;}\n",
    "div.prompt {min-width: 0ex; padding: 0px;}\n",
    ".container {width:95% !important;}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autosave 0\n",
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from tqdm import tqdm_notebook\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset y dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "import sklearn.model_selection\n",
    "\n",
    "mnist_train_data = torchvision.datasets.MNIST('dataset', train=True, download=True, \n",
    "                                              transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "fig, ax = plt.subplots(1, 10, figsize=(8, 2), tight_layout=True)\n",
    "for k in range(10):\n",
    "    image, label = mnist_train_data[k]\n",
    "    ax[k].imshow(image.numpy()[0, :, :], cmap=plt.cm.Greys_r)\n",
    "    ax[k].axis('off');\n",
    "    ax[k].set_title(label)\n",
    "    \n",
    "sss = sklearn.model_selection.StratifiedShuffleSplit(train_size=0.6)\n",
    "train_idx, valid_idx = next(sss.split(np.zeros(len(mnist_train_data)), mnist_train_data.targets))\n",
    "\n",
    "train_dataset = Subset(mnist_train_data, train_idx)\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=32)\n",
    "valid_dataset = Subset(mnist_train_data, valid_idx)\n",
    "valid_loader = DataLoader(valid_dataset, shuffle=False, batch_size=256)\n",
    "\n",
    "mnist_test_data = torchvision.datasets.MNIST('dataset', train=False, download=True,\n",
    "                                             transform=torchvision.transforms.ToTensor())\n",
    "test_loader = DataLoader(mnist_test_data, shuffle=False, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mi_autoencoder(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(mi_autoencoder, self).__init__()\n",
    "        # Llenar\n",
    "    \n",
    "    def encode(self, x):\n",
    "        # Llenar        \n",
    "        return x\n",
    "        \n",
    "    def decode(self, z):\n",
    "        # Llenar\n",
    "        return z\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = self.encode(x)\n",
    "        return self.decode(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nnet = mi_autoencoder()\n",
    "optimizer = torch.optim.Adam(nnet.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction='sum')\n",
    "use_gpu = False\n",
    "nepochs = 5\n",
    "if use_gpu:\n",
    "    nnet = nnet.cuda()\n",
    "\n",
    "import time\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# tensorboard --logdir=/tmp/tensorboard\n",
    "current_time = str(time.time_ns())\n",
    "train_writer = SummaryWriter(\"/tmp/tensorboard/ae/\"+current_time+\"/train/\", flush_secs=10)\n",
    "valid_writer = SummaryWriter(\"/tmp/tensorboard/ae/\"+current_time+\"/valid/\", flush_secs=10)\n",
    "\n",
    "for epoch in range(nepochs): \n",
    "    # Train\n",
    "    epoch_loss = 0.0\n",
    "    for mbdata, mblabel in train_loader:\n",
    "        if use_gpu:\n",
    "            mbdata, mblabel = mbdata.cuda(), mblabel.cuda()\n",
    "        prediction = nnet(mbdata)\n",
    "        optimizer.zero_grad()        \n",
    "        loss = criterion(prediction, mbdata)\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_writer.add_scalar('Loss', epoch_loss/len(train_idx), epoch)\n",
    "    # Validation    \n",
    "    epoch_loss = 0.0\n",
    "    for mbdata, mblabel in valid_loader:\n",
    "        if use_gpu:\n",
    "            mbdata, mblabel = mbdata.cuda(), mblabel.cuda()\n",
    "        prediction = nnet(mbdata)\n",
    "        loss = criterion(prediction, mbdata)\n",
    "        epoch_loss += loss.item()\n",
    "    valid_writer.add_scalar('Loss', epoch_loss/len(valid_idx), epoch)\n",
    "\n",
    "if use_gpu:\n",
    "    nnet = nnet.cpu()\n",
    "    \n",
    "train_writer.close()\n",
    "valid_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizaci贸n de las reconstrucciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 10, figsize=(8, 3))\n",
    "P = np.random.permutation(10000)\n",
    "\n",
    "for i in range(10):\n",
    "    image, label = mnist_test_data[P[i]]\n",
    "    hat_image = torch.nn.Sigmoid()(nnet.forward(image.unsqueeze(0)))\n",
    "    axs[0, i].matshow(image.numpy()[0, :, :], cmap=plt.cm.Greys_r)\n",
    "    axs[0, i].axis('off');\n",
    "    axs[0, i].set_title(label)\n",
    "    axs[1, i].matshow(hat_image.detach().numpy()[0, 0, :, :], cmap=plt.cm.Greys_r)\n",
    "    axs[1, i].axis('off');\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizaci贸n del espacio latente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 4), dpi=80)\n",
    "ax_main = plt.subplot2grid((2, 3), (0, 0), colspan=2, rowspan=2)\n",
    "ax_ori = plt.subplot2grid((2, 3), (0, 2))\n",
    "ax_rec = plt.subplot2grid((2, 3), (1, 2))\n",
    "ax_ori.axis('off'); ax_rec.axis('off');\n",
    "\n",
    "z_eval = np.zeros(shape=(len(mnist_test_data), 2))\n",
    "for i, (image, label) in enumerate(test_loader):\n",
    "    z_eval[i*256:(i+1)*256] = nnet.encode(image).detach().numpy()\n",
    "\n",
    "for t in range(10):\n",
    "    ax_main.scatter(z_eval[mnist_test_data.targets.numpy() == t, 0], \n",
    "                    z_eval[mnist_test_data.targets.numpy() == t, 1], s=5, alpha=0.5, label=str(t))\n",
    "ax_main.legend();\n",
    "\n",
    "def onclick(event):\n",
    "    z_closest = [event.xdata, event.ydata]\n",
    "    idx = np.argmin(np.sum((z_eval - z_closest)**2, axis=1))\n",
    "    image, label = mnist_test_data[idx]\n",
    "    hat_image = torch.nn.Sigmoid()(nnet.forward(image.unsqueeze(0)))\n",
    "    ax_ori.matshow(mnist_test_data[idx][0].numpy()[0, :, :], cmap=plt.cm.Greys_r)\n",
    "    ax_rec.matshow(hat_image.detach().numpy()[0, 0, :, :], cmap=plt.cm.Greys_r)\n",
    "    \n",
    "cid = fig.canvas.mpl_connect('button_press_event', onclick)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backup: Versi贸n antigua en tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Use this to select GPU and limit the memory usage\n",
    "\n",
    "\"\"\"\n",
    "environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "\n",
    "nepochs = 20\n",
    "batch_size = 32\n",
    "metrics = np.zeros(shape=(nepochs, 2))\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "#with tf.variable_scope('encoder'):\n",
    "#    h = tf.layers.dense(inputs=x, units=64, use_bias=True, activation=tf.nn.relu)\n",
    "with tf.variable_scope('latent'):\n",
    "    z = tf.layers.dense(inputs=x, units=2, use_bias=True, activation=None)\n",
    "with tf.variable_scope('decoder'):\n",
    "    #h = tf.layers.dense(inputs=z, units=64, use_bias=True, activation=tf.nn.relu)\n",
    "    y = tf.layers.dense(inputs=z, units=784, use_bias=True, activation=None)\n",
    "    x_hat = tf.nn.sigmoid(y)\n",
    "\n",
    "cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(logits=y, labels=x)\n",
    "reg = tf.reduce_mean(tf.norm(z, ord=2))\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "beta = 0.0\n",
    "train_step = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(loss + beta*reg)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 3), dpi=80)\n",
    "ax.plot(0, linewidth=2, alpha=0.75, label='Train'); \n",
    "ax.plot(0, linewidth=2, alpha=0.75, label='Test');\n",
    "ax.set_ylabel('Loss'); ax.set_xlabel('Epoch')\n",
    "line1, line2 = ax.lines\n",
    "plt.legend(); plt.grid(); plt.tight_layout();\n",
    "\n",
    "with tf.Session(config=config) as sess:    \n",
    "    tf.global_variables_initializer().run()\n",
    "    for epoch in tqdm_notebook(range(nepochs), desc='Train epoch'):\n",
    "        for _ in range(int(mnist.train.images.shape[0]/batch_size)):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step, feed_dict={x: batch_xs})\n",
    "        metrics[epoch, 0] = sess.run(loss, feed_dict={x: mnist.train.images})\n",
    "        metrics[epoch, 1] = sess.run(loss, feed_dict={x: mnist.test.images})\n",
    "        if epoch > 0:\n",
    "            line1.set_data(range(epoch+1), metrics[:epoch+1, 0])\n",
    "            line2.set_data(range(epoch+1), metrics[:epoch+1, 1])\n",
    "            ax.set_xlim([0, epoch])\n",
    "            ax.set_ylim([np.amin(metrics[:epoch+1,:]), np.amax(metrics[:epoch+1,:])])\n",
    "            fig.canvas.draw()\n",
    "    z_eval = sess.run(z, feed_dict={x: mnist.test.images})\n",
    "    x_hat_eval = sess.run(x_hat, feed_dict={x: mnist.test.images})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
